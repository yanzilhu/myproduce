/home/h/miniconda3/envs/p3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.
  rank_zero_deprecation(
/home/h/miniconda3/envs/p3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:578: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.
  rank_zero_deprecation(
Auto select gpus: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
In train loop....
You are using a CUDA device ('NVIDIA GeForce RTX 5090 D') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name              | Type                | Params
----------------------------------------------------------
0 | depth_loss_init   | Silog_loss_variance | 0
1 | depth_loss_offset | Silog_loss_variance | 0
2 | depth_loss_final  | Silog_loss_variance | 0
3 | net               | StructRankNetPQRS   | 94.2 M
----------------------------------------------------------
84.4 M    Trainable params
9.8 M     Non-trainable params
94.2 M    Total params
376.999   Total estimated model params size (MB)
Epoch 0:  25%|‚ñè| 727/2920 [05:07<15:28,  2.36it/s, loss=30.4, v_num=awz4, loss_depth=6.710, loss_depth_offset=6.760, loss_depth_final=13.50, loss_tot                                                               
/home/h/miniconda3/envs/p3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/h/miniconda3/envs/p3d/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
[34m[1mwandb[0m: [33mWARNING[0m Data passed to `wandb.Image` should consist of values in the range [0, 255], image data will be normalized to this range, but behavior will be removed in a future version of wandb.
